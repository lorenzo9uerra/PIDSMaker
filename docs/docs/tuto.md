In this tutorial, we craft a brand new architecture using existing components in the framework and evaluate it on node-level intrusion detection.

## Architecture

Our goal is to create a new system that captures whether nodes are source or destination, then uses a GraphSAGE model to capture structural patterns in the provenance graph.
The node embeddings generated by the encoder are then fed to a 2-layer MLP decoder and we train the model in a self-supervised manner to predict edge types, similarly as in the Kairos and Orthrus systems.
In a final step, we aim to threshold the predict malicious scores if their predicted scores exceed a threshold, computed as the max loss seen on the validation set.

**Approach**: We will craft a new encoder and intgrate it in the framework in such a way that it can be used from arguments. We will then create a YML config describing our system's pipeline and will execute it.

### Requirements

- A GPU with >20GB memory
- 16GB of RAM
- 30GB of storage
- follow the [installation guidelines](ten-minute-install.md) and have a shell opened in the pids container

## Integrate a new encoder

In this example, we implement a new encoder that captures whether nodes are source or destination, then uses a GraphSAGE model to capture structural patterns in the provenance graph.


``` py title="encoders/custom_encoder.py"
import torch.nn as nn

from pidsmaker.encoders import SAGE


class CustomEncoder(nn.Module):
    def __init__(self, in_dim, hid_dim, out_dim, graph_reindexer, activation, dropout, num_layers, device):
        super().__init__()

        self.src_proj = nn.Linear(in_dim, hid_dim)
        self.dst_proj = nn.Linear(in_dim, hid_dim)
        
        self.sage = SAGE(
            in_dim=hid_dim,
            hid_dim=hid_dim,
            out_dim=out_dim,
            activation=activation,
            dropout=dropout,
            num_layers=num_layers,
        )

        self.graph_reindexer = graph_reindexer

    def forward(self, x_src, x_dst, edge_index, **kwargs):
        # Project source and destination nodes in a separate embedding space
        h_src = self.src_proj(x_src)  # (E, d)
        h_dst = self.dst_proj(x_dst)  # (E, d)
        
        # Reshape features to (N, d)
        h_src_N, h_dst_N = self.graph_reindexer.node_features_reshape(edge_index, h_src, h_dst, x_is_tuple=True)
        h = h_src_N + h_dst_N  # (N, d)

        # Pass them through a SAGE GNN
        return self.sage(h, edge_index)
```

In this example, only two arguments are specific to the encoder and are not globally shared by all encoders: the `activation` function and the `num_layers` in the GNN. We want to let the user set those arguments via the config file so that it can experiment different values.
To do so, we need to create a new set of arguments specifically for this encoder.

``` py title="config/config.py"
ENCODERS_CFG = {
    ...
    "custom_encoder": {
        "activation": str,
        "num_layers": int,
    },
}
```

!!! note
    If an encoder doesn't rely on any custom arguments, simply leave the dict empty: `"custom_encoder": {}`, but every encoder should be defined here, or it will not be recognized by the framework.

All the logic about components' instantiation can be found in `factory.py`. Let's create a new case in `encoder_factory()` for our new encoder. The `graph_reindexer` is already instanciated and can be reused. Here, `custom_encoder` is the name of our encoder that we will later specify in the config.

``` py hl_lines="9 10 11" title="factory.py: encoder_factory()"
    ...
    elif method == "custom_encoder":
        encoder = CustomEncoder(
            in_dim=in_dim,
            hid_dim=node_hid_dim,
            out_dim=node_out_dim,
            dropout=dropout,
            graph_reindexer=graph_reindexer,
            activation=activation_fn_factory(
                cfg.detection.gnn_training.encoder.custom_encoder.activation),
            num_layers=cfg.detection.gnn_training.encoder.custom_encoder.num_layers,
            device=device,
        )
```

Our new argument `activation` can be accessed from the `cfg` object via `cfg.detection.gnn_training.encoder.custom_encoder.activation`.

Then add the encoder to the list of available encoders in `__init__.py`.

``` py title="encoders/__init__.py"
...
from .custom_encoder import CustomEncoder
```

## Integrate a new system

To integrate a new system, first create a new YAML file: `config/custom_system.yml`. This file describes all the logic of our new PIDS pipeline.
In this example, we take `orthrus` as base configuration. We only override necessary arguments and keep the `featurization` task unchanged, using word2vec to embed textual paths and IP addresses, and we use the same `evaluation` task, based on node-level detection.

**Config:**

``` yaml title="config/custom_system.yml" linenums="1"
_include_yml: orthrus

preprocessing:
  build_graphs:
    time_window_size: 15.0

detection:
  graph_preprocessing:
    intra_graph_batching:
      used_methods: none
  
  gnn_training:
    lr: 0.0001
    node_hid_dim: 128
    node_out_dim: 128

    encoder:
      dropout: 0.3
      used_methods: custom_encoder
      custom_encoder:
        activation: relu
        num_layers: 3
```

- **Line 1**: in this example, we take the `orthrus` system as base configuration
- **Line 5**: we partition the graphs in time windows of size 15 minutes
- **Line 10**: by default `orthrus` partitions each time window in even smaller batches of 1024 edges. To discard this behavior, we set `used_methods: None`
- **Lines 13-15**: we set some custom hyperparameters for training
- **Line 19**: it's here that we tell the encoder to use, in this case our new `custom_encoder`
- **Lines 21-22**: we set the values for our two defined arguments: `activation` and `num_layers`

## Run the pipeline

In the pids container, ensure you have logged to weights and biases (W&B) with `wandb login` and run:

``` sh
cd scripts
./run.sh custom_system CADETS_E3 --project=test_custom_model
```

